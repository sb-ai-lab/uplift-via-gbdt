{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8ee1a3a",
   "metadata": {},
   "source": [
    "## Run GPU baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6aec6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import Queue\n",
    "\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926f499c",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af193cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "DEVICE_LIST = [0, 1]\n",
    "N_JOBS = 4\n",
    "N_TASKS_PER_DEVICE = 1 # since utilization is not high, some of the tasks could be ran on the same device\n",
    "PYTHON = '../rapids-24.04/bin/python'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d63ff46",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb12f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill GPU queue\n",
    "QUEUE = Queue(maxsize=len(DEVICE_LIST) * N_TASKS_PER_DEVICE)\n",
    "for i in range(len(DEVICE_LIST)):\n",
    "    for _ in range(N_TASKS_PER_DEVICE):\n",
    "        QUEUE.put(i)\n",
    "    \n",
    "# run script to execute the task\n",
    "def get_script(path, runner, tuner, model, device):\n",
    "    \"\"\"\n",
    "    Get run script for the task\n",
    "    \"\"\"\n",
    "    command = f\"\"\"\n",
    "    {PYTHON} run_experiment.py \\\n",
    "        --path {os.path.join('datasets', path)} \\\n",
    "        --njobs {N_JOBS} \\\n",
    "        --seed 42 \\\n",
    "        --device {device} \\\n",
    "        --runner {runner} \\\n",
    "        --tuner {tuner} \\\n",
    "        --model {model} \\\n",
    "        --config config.yaml\n",
    "    \"\"\"\n",
    "    return command\n",
    "\n",
    "\n",
    "def run(path, model, runner, tuner, ):\n",
    "    \"\"\"\n",
    "    Run task\n",
    "    \"\"\"\n",
    "    # get free GPU\n",
    "    device = QUEUE.get()\n",
    "    # generate script\n",
    "    print('Task started')\n",
    "    script = get_script(path, runner, tuner, model, device)\n",
    "    print(script)\n",
    "    # run task\n",
    "    subprocess.check_output(script, shell=True, stderr=subprocess.STDOUT,)\n",
    "    # back to queue\n",
    "    QUEUE.put(device)\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e48e344",
   "metadata": {},
   "source": [
    "### Tasks list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee65812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tasks list\n",
    "datasets = [\n",
    "    \n",
    "    'synth1', \n",
    "#     'hillstrom', \n",
    "#     'criteo',\n",
    "#     'lenta',\n",
    "#     'megafon',\n",
    "]\n",
    "\n",
    "# tuple: (type of model, run function, objective with param space)\n",
    "models = [\n",
    "    # py-boost baseline\n",
    "    # ('pb_lc_f_t', 'pb', 'pb'), \n",
    "    # dragonnet\n",
    "    ('dr', 'dr', 'dr'),\n",
    "    # DESCN\n",
    "    # ('dcn', 'dr', 'dcn')\n",
    "]\n",
    "\n",
    "# combine datasets and models\n",
    "tasks = product(\n",
    "    map(\n",
    "        lambda x: x[0] + '_' + str(x[1]), product(datasets, range(5))\n",
    "    ),\n",
    "    models\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ebf10b",
   "metadata": {},
   "source": [
    "### Run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933db84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Parallel(len(DEVICE_LIST) * N_TASKS_PER_DEVICE, backend='threading') as p:\n",
    "    p(delayed(run)(d, *m) for (d, m) in tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ee3f26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
